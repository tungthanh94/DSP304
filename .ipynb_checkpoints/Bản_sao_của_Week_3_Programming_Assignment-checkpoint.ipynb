{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJQu9UWtRfRx"
   },
   "source": [
    "# Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFRRArflRfR1"
   },
   "source": [
    "## Language model for the Shakespeare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2j_QtDXtRfR4"
   },
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# If you would like to make further imports from tensorflow, add them here\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3wpZrx7RfR-"
   },
   "source": [
    "#### The Shakespeare dataset\n",
    "\n",
    "In this assignment, you will use a subset of the [Shakespeare dataset](http://shakespeare.mit.edu). It consists of a single text file with several excerpts concatenated together. The data is in raw text form, and so far has not yet had any preprocessing. \n",
    "\n",
    "Your goal is to construct an unsupervised character-level sequence model that can generate text according to a distribution learned from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XZu3DSPRkE4"
   },
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset required for this project can be downloaded from the following link:\n",
    "\n",
    "https://drive.google.com/open?id=1pQI1ryDnuMKl5FtgBI9k9vXQ65S8xLv2\n",
    "\n",
    "You should store this file in Drive for use in this Colab notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppOL7TDHRfSA"
   },
   "source": [
    "#### Load and inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XXwzWcB-RfSD"
   },
   "outputs": [],
   "source": [
    "# Load the text file into a string\n",
    "\n",
    "with open('Shakespeare.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlWdBq04eSTn",
    "outputId": "cc352272-8da2-413f-b37c-b74ac527b6d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81PNt2hPeVBZ",
    "outputId": "b5dd4721-9d45-4a5c-bcb5-4a49511f763b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YzHw4wbCRfSH"
   },
   "outputs": [],
   "source": [
    "# Create a list of chunks of text\n",
    "\n",
    "text_chunks = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ivomkSYkeZka",
    "outputId": "41fc24fe-6b2d-47b5-de48-61813bd9ef15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXEU0khzfjRj",
    "outputId": "333da993-ad1d-4e30-c993-d325f7fb8d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:\\nBefore we proceed any further, hear me speak',\n",
       " '\\n\\nAll:\\nSpeak, speak',\n",
       " '\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved',\n",
       " ' resolved',\n",
       " '\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people',\n",
       " \"\\n\\nAll:\\nWe know't, we know't\",\n",
       " \"\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price\",\n",
       " \"\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens\",\n",
       " '\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good',\n",
       " '\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pik73Zq2RfSO"
   },
   "source": [
    "To give you a feel for what the text looks like, we will print a few chunks from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMZj2MIYRfSP",
    "outputId": "3f73eb0e-bf9c-4493-fcbb-2d792a78c37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "HERMIONE:\n",
      "That's true enough;\n",
      "Through 'tis a saying, sir, not due to me\n",
      "\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Against all sense you do importune her:\n",
      "Should she kneel down in mercy of this fact,\n",
      "Her brother's ghost his paved bed would break,\n",
      "And take her hence in horror\n",
      " Leave me\n",
      "awhile with the maid: my mind promises with my\n",
      "habit no loss shall touch her by my company\n",
      "\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "Whither?\n",
      "\n",
      "KING RICHARD II:\n",
      "Whither you will, so I were from your sights\n",
      "\n",
      "\n",
      "LUCIO:\n",
      "O, did you so? And do you remember what you said of the duke?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Most notedly, sir\n"
     ]
    }
   ],
   "source": [
    "# Display some randomly selected text samples\n",
    "\n",
    "num_samples = 5\n",
    "inx = np.random.choice(len(text_chunks), num_samples, replace=False)\n",
    "for chunk in np.array(text_chunks)[inx]:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSxfAsFARfSX"
   },
   "source": [
    "#### Create a character-level tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBukx3SDRfSY"
   },
   "source": [
    "You should now write a function that returns a `Tokenizer` object. The function takes a list of strings as an argument, and should create a `Tokenizer` according to the following specification:\n",
    "\n",
    "* The number of tokens should be unlimited (there should be as many as required by the dataset).\n",
    "* Tokens should be created at the character level (not at the word level, which is the default behaviour).\n",
    "* No characters should be filtered out or ignored.\n",
    "* The original capitalization should be retained (do not convert the text to lower case)\n",
    "\n",
    "The `Tokenizer` should be fit to the `list_of_strings` argument and returned by the function. \n",
    "\n",
    "**Hint:** you may need to refer to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) for the `Tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qNknqeDNhWTE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q8s2aR4oRfSb"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def create_character_tokenizer(list_of_strings):\n",
    "    \"\"\"\n",
    "    This function takes a list of strings as its argument. It should create \n",
    "    and return a Tokenizer according to the above specifications. \n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(filters = None,\n",
    "                          lower = False,\n",
    "                          char_level = True)\n",
    "    tokenizer.fit_on_texts(list_of_strings)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aKZpIcn_RfSf"
   },
   "outputs": [],
   "source": [
    "# Get the tokenizer\n",
    "\n",
    "tokenizer = create_character_tokenizer(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4sKBLA1iYPn",
    "outputId": "598a6130-26ea-4d0f-9286-0b218e3604a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'e': 2,\n",
       " 't': 3,\n",
       " 'o': 4,\n",
       " 'a': 5,\n",
       " 'h': 6,\n",
       " 's': 7,\n",
       " 'r': 8,\n",
       " 'n': 9,\n",
       " 'i': 10,\n",
       " '\\n': 11,\n",
       " 'l': 12,\n",
       " 'd': 13,\n",
       " 'u': 14,\n",
       " 'm': 15,\n",
       " 'y': 16,\n",
       " ',': 17,\n",
       " 'w': 18,\n",
       " 'f': 19,\n",
       " 'c': 20,\n",
       " 'g': 21,\n",
       " 'I': 22,\n",
       " 'b': 23,\n",
       " 'p': 24,\n",
       " ':': 25,\n",
       " 'A': 26,\n",
       " 'v': 27,\n",
       " 'k': 28,\n",
       " 'T': 29,\n",
       " \"'\": 30,\n",
       " 'E': 31,\n",
       " 'O': 32,\n",
       " 'N': 33,\n",
       " 'R': 34,\n",
       " 'S': 35,\n",
       " 'L': 36,\n",
       " 'C': 37,\n",
       " ';': 38,\n",
       " 'W': 39,\n",
       " 'U': 40,\n",
       " 'H': 41,\n",
       " 'M': 42,\n",
       " 'B': 43,\n",
       " '?': 44,\n",
       " 'G': 45,\n",
       " '!': 46,\n",
       " 'D': 47,\n",
       " '-': 48,\n",
       " 'F': 49,\n",
       " 'Y': 50,\n",
       " 'P': 51,\n",
       " 'K': 52,\n",
       " 'V': 53,\n",
       " 'j': 54,\n",
       " 'q': 55,\n",
       " 'x': 56,\n",
       " 'z': 57,\n",
       " 'J': 58,\n",
       " 'Q': 59,\n",
       " 'Z': 60,\n",
       " 'X': 61,\n",
       " '3': 62,\n",
       " '&': 63,\n",
       " '$': 64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWObVg6DRfSi"
   },
   "source": [
    "#### Tokenize the text\n",
    "\n",
    "You should now write a function to use the tokenizer to map each string in `text_chunks` to its corresponding encoded sequence. The following function takes a fitted `Tokenizer` object in the first argument (as returned by `create_character_tokenizer`) and a list of strings in the second argument. The function should return a list of lists, where each sublist is a sequence of integer tokens encoding the text sequences according to the mapping stored in the tokenizer.\n",
    "\n",
    "**Hint:** you may need to refer to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) for the `Tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lkKDCvV1RfSj"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def strings_to_sequences(tokenizer, list_of_strings):\n",
    "    \"\"\"\n",
    "    This function takes a tokenizer object and a list of strings as its arguments.\n",
    "    It should use the tokenizer to map the text chunks to sequences of tokens and\n",
    "    then return this list of encoded sequences.\n",
    "    \"\"\"\n",
    "    sequence = tokenizer.texts_to_sequences(list_of_strings)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hhYb2mSlRfSo"
   },
   "outputs": [],
   "source": [
    "# Encode the text chunks into tokens\n",
    "\n",
    "seq_chunks = strings_to_sequences(tokenizer, text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8Tjo0j8jJQh",
    "outputId": "616e9661-9752-4fe5-971a-9051fe6b6ec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7886"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7m5Ip9L6jKk4",
    "outputId": "433645b5-5f0c-409c-c3aa-fb2acb106b4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seq_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ul5wlGQ3j5Ac",
    "outputId": "7fe9d91a-49f2-4536-97ca-74cfea38224a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(i) for i in seq_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PKtPYw3viL_K",
    "outputId": "b04000d9-a31e-40bb-b411-6cb996877bd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuEFqHUNiDBn",
    "outputId": "35a36cad-6145-44e3-f4aa-b09c062736b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 37,\n",
       " 10,\n",
       " 3,\n",
       " 10,\n",
       " 57,\n",
       " 2,\n",
       " 9,\n",
       " 25,\n",
       " 11,\n",
       " 43,\n",
       " 2,\n",
       " 19,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 2,\n",
       " 1,\n",
       " 24,\n",
       " 8,\n",
       " 4,\n",
       " 20,\n",
       " 2,\n",
       " 2,\n",
       " 13,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 16,\n",
       " 1,\n",
       " 19,\n",
       " 14,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 17,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 15,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 24,\n",
       " 2,\n",
       " 5,\n",
       " 28]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRCN70xkRfSt"
   },
   "source": [
    "#### Pad the encoded sequences and store them in a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ucADRYoRfSu"
   },
   "source": [
    "Since not all of the text chunks are the same length, you will need to pad them in order to train on batches. You should now complete the following function, which takes the list of lists of tokens, and creates a single numpy array with the token sequences in the rows, according to the following specification:\n",
    "\n",
    "* The longest allowed sequence should be 500 tokens. Any sequence that is longer should be shortened by truncating the beginning of the sequence.\n",
    "* Use zeros for padding the sequences. The zero padding should be placed before the sequences as required.\n",
    "\n",
    "The function should then return the resulting numpy array.\n",
    "\n",
    "**Hint:** you may want to refer to the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) for the `pad_sequences` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "zLf-9KxWRfSw"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def make_padded_dataset(sequence_chunks):\n",
    "    \"\"\"\n",
    "    This function takes a list of lists of tokenized sequences, and transforms\n",
    "    them into a 2D numpy array, padding the sequences as necessary according to\n",
    "    the above specification. The function should then return the numpy array.\n",
    "    \"\"\"\n",
    "    padded = pad_sequences(sequence_chunks, maxlen = 500, padding = 'pre', truncating= 'pre')\n",
    "    return padded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IKB26MgJRfS0"
   },
   "outputs": [],
   "source": [
    "# Pad the token sequence chunks and get the numpy array\n",
    "\n",
    "padded_sequences = make_padded_dataset(seq_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxnR6_TIl5_6",
    "outputId": "da08f3a1-03cd-41af-d8de-5a55357a45d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtxDvD-zlD-H",
    "outputId": "803d3958-7e2e-4c67-b93f-09500b3cc757"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  2,  5, 28],\n",
       "       [ 0,  0,  0, ...,  2,  5, 28],\n",
       "       [ 0,  0,  0, ..., 27,  2, 13],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  2,  2, 24],\n",
       "       [ 0,  0,  0, ..., 10,  9, 21],\n",
       "       [ 0,  0,  0, ...,  0,  0, 11]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-4W2iICRfS3"
   },
   "source": [
    "#### Create model inputs and targets\n",
    "\n",
    "Now you are ready to build your RNN model. The model will receive a sequence of characters and predict the next character in the sequence. At training time, the model can be passed an input sequence, with the target sequence is shifted by one.\n",
    "\n",
    "For example, the expression `To be or not to be` appears in Shakespeare's play 'Hamlet'. Given input `To be or not to b`, the correct prediction is `o be or not to be`. Notice that the prediction is the same length as the input!\n",
    "\n",
    "![sequence_prediction_example](rnn_example.png)\n",
    "\n",
    "You should now write the following function to create an input and target array from the current `padded_sequences` array. The function has a single argument that is a 2D numpy array of shape `(num_examples, max_seq_len)`. It should fulfil the following specification:\n",
    "\n",
    "* The function should return an input array and an output array, both of size `(num_examples, max_seq_len - 1)`.\n",
    "* The input array should contain the first `max_seq_len - 1` tokens of each sequence. \n",
    "* The output array should contain the last `max_seq_len - 1` tokens of each sequence. \n",
    "\n",
    "The function should then return the tuple `(input_array, output_array)`. Note that it is possible to complete this function using numpy indexing alone!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pzLY5mT3RfS5"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def create_inputs_and_targets(array_of_sequences):\n",
    "    \"\"\"\n",
    "    This function takes a 2D numpy array of token sequences, and returns a tuple of two\n",
    "    elements: the first element is the input array and the second element is the output\n",
    "    array, which are defined according to the above specification.\n",
    "    \"\"\" \n",
    "    return array_of_sequences[:, :-1], array_of_sequences[:, 1:]  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "MzHXg9HcRfTB"
   },
   "outputs": [],
   "source": [
    "# Create the input and output arrays\n",
    "\n",
    "input_seq, target_seq = create_inputs_and_targets(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICRJl3oulwzc",
    "outputId": "13732c69-32f4-46ff-a8d3-4915dd523ec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 24,  2,  5],\n",
       "       [ 0,  0,  0, ..., 24,  2,  5],\n",
       "       [ 0,  0,  0, ..., 12, 27,  2],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 12,  2,  2],\n",
       "       [ 0,  0,  0, ..., 28, 10,  9],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjaWx5ALly2B",
    "outputId": "12724c93-5882-426d-8d40-72e966d032e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  2,  5, 28],\n",
       "       [ 0,  0,  0, ...,  2,  5, 28],\n",
       "       [ 0,  0,  0, ..., 27,  2, 13],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  2,  2, 24],\n",
       "       [ 0,  0,  0, ..., 10,  9, 21],\n",
       "       [ 0,  0,  0, ...,  0,  0, 11]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rvcKS4qyl19o",
    "outputId": "26501130-c164-489f-9959-88ba8943e2d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 499)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFTEK7hnRfTJ"
   },
   "source": [
    "#### Preprocess sequence array for stateful RNN\n",
    "\n",
    "We will build our RNN language model to be stateful, so that the internal state of the RNN will be maintained across batches. For this to be effective, we need to make sure that each element of every batch follows on from the corresponding element of the preceding batch (you may want to look back at the \"Stateful RNNs\" reading notebook earlier in the week).\n",
    "\n",
    "The following code processes the input and output sequence arrays so that they are ready to be split into batches for training a stateful RNN, by re-ordering the sequence examples (the rows) according to a specified batch size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "S4gsVamxRfTK"
   },
   "outputs": [],
   "source": [
    "# Fix the batch size for training\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "cJu9VgWFRfTP"
   },
   "outputs": [],
   "source": [
    "# Prepare input and output arrays for training the stateful RNN\n",
    "\n",
    "num_examples = input_seq.shape[0]\n",
    "\n",
    "num_processed_examples = num_examples - (num_examples % batch_size)\n",
    "\n",
    "input_seq = input_seq[:num_processed_examples]\n",
    "target_seq = target_seq[:num_processed_examples]\n",
    "\n",
    "steps = int(num_processed_examples / 32)  # steps per epoch\n",
    "\n",
    "inx = np.empty((0,), dtype=np.int32)\n",
    "for i in range(steps):\n",
    "    inx = np.concatenate((inx, i + np.arange(0, num_processed_examples, steps)))\n",
    "\n",
    "input_seq_stateful = input_seq[inx]\n",
    "target_seq_stateful = target_seq[inx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, num_processed_examples, steps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  246,  492,  738,  984, 1230, 1476, 1722, 1968, 2214, 2460,\n",
       "       2706, 2952, 3198, 3444, 3690, 3936, 4182, 4428, 4674, 4920, 5166,\n",
       "       5412, 5658, 5904, 6150, 6396, 6642, 6888, 7134, 7380, 7626])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, num_processed_examples, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626]\n",
      "32\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627]\n",
      "64\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628]\n",
      "96\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629]\n",
      "128\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630]\n",
      "160\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631]\n",
      "192\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632]\n",
      "224\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632\n",
      "    7  253  499  745  991 1237 1483 1729 1975 2221 2467 2713 2959 3205\n",
      " 3451 3697 3943 4189 4435 4681 4927 5173 5419 5665 5911 6157 6403 6649\n",
      " 6895 7141 7387 7633]\n",
      "256\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632\n",
      "    7  253  499  745  991 1237 1483 1729 1975 2221 2467 2713 2959 3205\n",
      " 3451 3697 3943 4189 4435 4681 4927 5173 5419 5665 5911 6157 6403 6649\n",
      " 6895 7141 7387 7633    8  254  500  746  992 1238 1484 1730 1976 2222\n",
      " 2468 2714 2960 3206 3452 3698 3944 4190 4436 4682 4928 5174 5420 5666\n",
      " 5912 6158 6404 6650 6896 7142 7388 7634]\n",
      "288\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632\n",
      "    7  253  499  745  991 1237 1483 1729 1975 2221 2467 2713 2959 3205\n",
      " 3451 3697 3943 4189 4435 4681 4927 5173 5419 5665 5911 6157 6403 6649\n",
      " 6895 7141 7387 7633    8  254  500  746  992 1238 1484 1730 1976 2222\n",
      " 2468 2714 2960 3206 3452 3698 3944 4190 4436 4682 4928 5174 5420 5666\n",
      " 5912 6158 6404 6650 6896 7142 7388 7634    9  255  501  747  993 1239\n",
      " 1485 1731 1977 2223 2469 2715 2961 3207 3453 3699 3945 4191 4437 4683\n",
      " 4929 5175 5421 5667 5913 6159 6405 6651 6897 7143 7389 7635]\n",
      "320\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.empty((0,), dtype=np.int32)\n",
    "for i in range(10):\n",
    "    a = np.concatenate((a, i + np.arange(0, num_processed_examples, steps)))\n",
    "    print(a)\n",
    "    print(len(a))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626]\n",
      "32\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627]\n",
      "64\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628]\n",
      "96\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629]\n",
      "128\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630]\n",
      "160\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631]\n",
      "192\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632]\n",
      "224\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632\n",
      "    7  253  499  745  991 1237 1483 1729 1975 2221 2467 2713 2959 3205\n",
      " 3451 3697 3943 4189 4435 4681 4927 5173 5419 5665 5911 6157 6403 6649\n",
      " 6895 7141 7387 7633]\n",
      "256\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632\n",
      "    7  253  499  745  991 1237 1483 1729 1975 2221 2467 2713 2959 3205\n",
      " 3451 3697 3943 4189 4435 4681 4927 5173 5419 5665 5911 6157 6403 6649\n",
      " 6895 7141 7387 7633    8  254  500  746  992 1238 1484 1730 1976 2222\n",
      " 2468 2714 2960 3206 3452 3698 3944 4190 4436 4682 4928 5174 5420 5666\n",
      " 5912 6158 6404 6650 6896 7142 7388 7634]\n",
      "288\n",
      "\n",
      "\n",
      "[   0  246  492  738  984 1230 1476 1722 1968 2214 2460 2706 2952 3198\n",
      " 3444 3690 3936 4182 4428 4674 4920 5166 5412 5658 5904 6150 6396 6642\n",
      " 6888 7134 7380 7626    1  247  493  739  985 1231 1477 1723 1969 2215\n",
      " 2461 2707 2953 3199 3445 3691 3937 4183 4429 4675 4921 5167 5413 5659\n",
      " 5905 6151 6397 6643 6889 7135 7381 7627    2  248  494  740  986 1232\n",
      " 1478 1724 1970 2216 2462 2708 2954 3200 3446 3692 3938 4184 4430 4676\n",
      " 4922 5168 5414 5660 5906 6152 6398 6644 6890 7136 7382 7628    3  249\n",
      "  495  741  987 1233 1479 1725 1971 2217 2463 2709 2955 3201 3447 3693\n",
      " 3939 4185 4431 4677 4923 5169 5415 5661 5907 6153 6399 6645 6891 7137\n",
      " 7383 7629    4  250  496  742  988 1234 1480 1726 1972 2218 2464 2710\n",
      " 2956 3202 3448 3694 3940 4186 4432 4678 4924 5170 5416 5662 5908 6154\n",
      " 6400 6646 6892 7138 7384 7630    5  251  497  743  989 1235 1481 1727\n",
      " 1973 2219 2465 2711 2957 3203 3449 3695 3941 4187 4433 4679 4925 5171\n",
      " 5417 5663 5909 6155 6401 6647 6893 7139 7385 7631    6  252  498  744\n",
      "  990 1236 1482 1728 1974 2220 2466 2712 2958 3204 3450 3696 3942 4188\n",
      " 4434 4680 4926 5172 5418 5664 5910 6156 6402 6648 6894 7140 7386 7632\n",
      "    7  253  499  745  991 1237 1483 1729 1975 2221 2467 2713 2959 3205\n",
      " 3451 3697 3943 4189 4435 4681 4927 5173 5419 5665 5911 6157 6403 6649\n",
      " 6895 7141 7387 7633    8  254  500  746  992 1238 1484 1730 1976 2222\n",
      " 2468 2714 2960 3206 3452 3698 3944 4190 4436 4682 4928 5174 5420 5666\n",
      " 5912 6158 6404 6650 6896 7142 7388 7634    9  255  501  747  993 1239\n",
      " 1485 1731 1977 2223 2469 2715 2961 3207 3453 3699 3945 4191 4437 4683\n",
      " 4929 5175 5421 5667 5913 6159 6405 6651 6897 7143 7389 7635]\n",
      "320\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.array([], dtype=np.int32)\n",
    "for i in range(10):\n",
    "    a = np.concatenate((a, i + np.arange(0, num_processed_examples, steps)))\n",
    "    print(a)\n",
    "    print(len(a))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  246,  492,  738,  984, 1230, 1476, 1722, 1968, 2214, 2460,\n",
       "       2706, 2952, 3198, 3444, 3690, 3936, 4182, 4428, 4674, 4920, 5166,\n",
       "       5412, 5658, 5904, 6150, 6396, 6642, 6888, 7134, 7380, 7626])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.empty((0,), dtype = np.int32), 0 +  np.arange(0, num_processed_examples, steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7872"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "246*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sVq9leBpV81",
    "outputId": "2dec56e9-21c9-41e0-c972-d754d3e877eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7886"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0EZTCEkpYEg",
    "outputId": "598ee221-ad36-42fd-aa91-8eedc16e4d90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7872"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_processed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmp1Xm8GpX5b",
    "outputId": "253e92e6-79c9-4416-8a71-1a091bdfa70b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_processed_examples / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjBR8jK-rHWh",
    "outputId": "28f23e48-08f4-48aa-d198-8b2de3b7277a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7872,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQYkEPSzqhsT",
    "outputId": "dbe80a65-cd1e-4b4f-ffb5-80006f9b889a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,  246,  492, ..., 7379, 7625, 7871])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cejjNlWrtWY",
    "outputId": "0b5b6422-bd4e-4a2c-8947-c72ef6a3c28a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7872, 499)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_stateful.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8fwDEMMrujG",
    "outputId": "b87bffce-505c-4776-ea09-509c6220e93c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 24,  2,  5],\n",
       "       [ 0,  0,  0, ..., 24,  2,  5],\n",
       "       [ 0,  0,  0, ..., 12, 27,  2],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  9, 21,  8],\n",
       "       [ 0,  0,  0, ...,  5, 28, 12],\n",
       "       [ 0,  0,  0, ...,  8,  1, 14]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EZ_YFITr0vm",
    "outputId": "dab7ddfc-1397-42dd-8f42-77a53f205ef8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 24,  2,  5],\n",
       "       [ 0,  0,  0, ...,  1, 16,  4],\n",
       "       [ 0,  0,  0, ...,  1,  9,  4],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  9,  3, 10],\n",
       "       [ 0,  0,  0, ...,  1,  6,  2],\n",
       "       [ 0,  0,  0, ...,  8,  1, 14]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_stateful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm8gNoNJRfTT"
   },
   "source": [
    "#### Split the data into training and validation sets\n",
    "\n",
    "We will set aside approximately 20% of the data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "iiLWfyemRfTU"
   },
   "outputs": [],
   "source": [
    "# Create the training and validation splits\n",
    "\n",
    "num_train_examples = int(batch_size * ((0.8 * num_processed_examples) // batch_size))\n",
    "\n",
    "input_train = input_seq_stateful[:num_train_examples]\n",
    "target_train = target_seq_stateful[:num_train_examples]\n",
    "\n",
    "input_valid = input_seq_stateful[num_train_examples:]\n",
    "target_valid = target_seq_stateful[num_train_examples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPtbqzcmtDim",
    "outputId": "d6e9882a-f3f3-4cbe-f7f2-1dc08a23b53f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6297.6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 * num_processed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CuMAR92hscJi",
    "outputId": "c04580c1-128e-49e9-9026-e4ea17bc24b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 * num_processed_examples// batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vFFJy59sA7V",
    "outputId": "f74ea59e-3684-45fc-bf37-f2b728a000ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQ_mAEoPRfTX"
   },
   "source": [
    "#### Create training and validation Dataset objects\n",
    "\n",
    "You should now write a function to take the training and validation input and target arrays, and create training and validation `tf.data.Dataset` objects. The function takes an input array and target array in the first two arguments, and the batch size in the third argument. Your function should do the following:\n",
    "\n",
    "* Create a `Dataset` using the `from_tensor_slices` static method, passing in a tuple of the input and output numpy arrays.\n",
    "* Batch the `Dataset` using the `batch_size` argument, setting `drop_remainder` to `True`. \n",
    "\n",
    "The function should then return the `Dataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_DJAjEHKRfTY"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def make_Dataset(input_array, target_array, batch_size):\n",
    "    \"\"\"\n",
    "    This function takes two 2D numpy arrays in the first two arguments, and an integer\n",
    "    batch_size in the third argument. It should create and return a Dataset object \n",
    "    using the two numpy arrays and batch size according to the above specification.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_array, target_array))\n",
    "    dataset = dataset.batch(batch_size, drop_remainder = True)\n",
    "    return dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "rzqK_qVARfTc"
   },
   "outputs": [],
   "source": [
    "# Create the training and validation Datasets\n",
    "\n",
    "train_data = make_Dataset(input_train, target_train, batch_size)\n",
    "valid_data = make_Dataset(input_valid, target_valid, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgEyLt0R25WF",
    "outputId": "7f6a3f46-67cc-42e7-ca26-fea763dfc13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((32, 499), (32, 499)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6D96J5Z28Y0",
    "outputId": "f5dbce52-22a8-4aa8-ac42-f2eea0066d8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((32, 499), (32, 499)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKfaWcCCRfTf"
   },
   "source": [
    "#### Build the recurrent neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcPyteqDRfTh"
   },
   "source": [
    "You are now ready to build your RNN character-level language model. You should write the following function to build the model; the function takes arguments for the batch size and vocabulary size (number of tokens). Using the Sequential API, your function should build your model according to the following specifications:\n",
    "\n",
    "* The first layer should be an Embedding layer with an embedding dimension of 256 and set the vocabulary size to `vocab_size` from the function argument.\n",
    "* The Embedding layer should also mask the zero padding in the input sequences.\n",
    "* The Embedding layer should also set the `batch_input_shape` to `(batch_size, None)` (a fixed batch size is required for stateful RNNs).\n",
    "* The next layer should be a (uni-directional) GRU layer with 1024 units, set to be a stateful RNN layer.\n",
    "* The GRU layer should return the full sequence, instead of just the output state at the final time step.\n",
    "* The final layer should be a Dense layer with `vocab_size` units and no activation function.\n",
    "\n",
    "In total, the network should have 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "tUypwAJjqRGq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, GRU, LSTM, Flatten, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "oauekqOSRfTi"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def get_model(vocab_size, batch_size):\n",
    "    \"\"\"\n",
    "    This function takes a vocabulary size and batch size, and builds and returns a \n",
    "    Sequential model according to the above specification.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "            Embedding(vocab_size, 256, mask_zero= True, batch_input_shape = (batch_size, None)),\n",
    "            GRU(1024, stateful= True, return_sequences= True),\n",
    "            Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmmEfYo-RfTl",
    "outputId": "9a91e6ba-970a-4892-dd99-f2743db6cead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (32, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (32, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (32, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model and print the model summary\n",
    "\n",
    "model = get_model(len(tokenizer.word_index) +1, batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PJ4cU0YRfTo"
   },
   "source": [
    "#### Compile and train the model\n",
    "\n",
    "You are now ready to compile and train the model. For this model and dataset, the training time is very long. Therefore for this assignment it is not a requirement to train the model. We have pre-trained a model for you (using the code below) and saved the model weights, which can be loaded to get the model predictions. \n",
    "\n",
    "It is recommended to use accelerator hardware (e.g. using Colab) when training this model. It would also be beneficial to increase the size of the model, e.g. by stacking extra recurrent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "62k8AD8eRfTp"
   },
   "outputs": [],
   "source": [
    "# Choose whether to train a new model or load the pre-trained model\n",
    "\n",
    "skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "DJhnIUHSRfTt",
    "outputId": "305ef53a-bbe5-4dc4-baf2-3e6fb9bafd0d"
   },
   "outputs": [],
   "source": [
    "# Compile and train the model, or load pre-trained weights\n",
    "\n",
    "if not skip_training:\n",
    "    checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath='./models/ckpt',\n",
    "                                                           save_weights_only=True,\n",
    "                                                           save_best_only=True)\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    history = model.fit(train_data, epochs=15, validation_data=valid_data, \n",
    "                        validation_steps=50, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "yqjTlQyoRfTx",
    "outputId": "f9f0b102-634e-4b1f-b103-cab84dd8f127"
   },
   "outputs": [],
   "source": [
    "# Save model history as a json file, or load it if using pre-trained weights\n",
    "\n",
    "if not skip_training:\n",
    "    history_dict = dict()\n",
    "    for k, v in history.history.items():\n",
    "        history_dict[k] = [float(val) for val in history.history[k]]\n",
    "    with open('models/history.json', 'w+') as json_file:\n",
    "        json.dump(history_dict, json_file, sort_keys=True, indent=4)\n",
    "else:\n",
    "    with open('models/history.json', 'r') as json_file:\n",
    "        history_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upDpsmf9RfT2"
   },
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "gGpPk5bbRfT3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to plot accuracy vs epoch and loss vs epoch\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(history_dict['sparse_categorical_accuracy'])\n",
    "plt.plot(history_dict['val_sparse_categorical_accuracy'])\n",
    "plt.title('Accuracy vs. epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(np.arange(len(history_dict['sparse_categorical_accuracy'])))\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(1 + np.arange(len(history_dict['sparse_categorical_accuracy'])))\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history_dict['loss'])\n",
    "plt.plot(history_dict['val_loss'])\n",
    "plt.title('Loss vs. epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(np.arange(len(history_dict['sparse_categorical_accuracy'])))\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(1 + np.arange(len(history_dict['sparse_categorical_accuracy'])))\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2msBeLSoRfT7"
   },
   "source": [
    "#### Write a text generation algorithm\n",
    "\n",
    "You can now use the model to generate text! In order to generate a single text sequence, the model needs to be rebuilt with a batch size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "zzQW69qxRfT_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.layers.embeddings.Embedding object at 0x00000240855E47C0> and <keras.layers.recurrent_v2.GRU object at 0x00000240855E41F0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.layers.recurrent_v2.GRU object at 0x00000240855E41F0> and <keras.layers.core.Dense object at 0x00000240855E40A0>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x240855e8f10>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-build the model and load the saved weights\n",
    "\n",
    "model = get_model(len(tokenizer.word_index) + 1, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint('./models/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM3LHQAgRfUD"
   },
   "source": [
    "An algorithm to generate text is as follows:\n",
    "\n",
    "1. Specify a seed string (e.g. `'ROMEO:'`) to get the network started, and a define number of characters for the model to generate, `num_generation_steps`.\n",
    "2. Tokenize this sentence to obtain a list containing one list of the integer tokens.\n",
    "3. Reset the initial state of the network. \n",
    "4. Convert the token list into a Tensor (or numpy array) and pass it to your model as a batch of size one.\n",
    "5. Get the model prediction (logits) for the last time step and extract the state of the recurrent layer.\n",
    "6. Use the logits to construct a categorical distribution and sample a token from it.\n",
    "7. Repeat the following for `num_generation_steps - 1` steps:\n",
    "\n",
    "    1. Use the saved state of the recurrent layer and the last sampled token to get new logit predictions\n",
    "    2. Use the logits to construct a new categorical distribution and sample a token from it.\n",
    "    3. Save the updated state of the recurrent layer.    \n",
    "\n",
    "8. Take the final list of tokens and convert to text using the Tokenizer.\n",
    "\n",
    "Note that the internal state of the recurrent layer can be accessed using the `states` property. For the GRU layer, it is a list of one variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "DDbzdt0LRfUE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gru_stateful/Variable:0' shape=(1, 1024) dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the model's current recurrent state\n",
    "\n",
    "model.layers[1].states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gru_stateful/Variable:0' shape=(1, 1024) dtype=float32, numpy=array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('gru_stateful').states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KvmtkvrRfUI"
   },
   "source": [
    "We will break the algorithm down into two steps. First, you should now complete the following function that takes a sequence of tokens of any length and returns the model's prediction (the logits) for the last time step. The specification is as follows:\n",
    "\n",
    "* The token sequence will be a python list, containing one list of integer tokens, e.g. `[[1, 2, 3, 4]]`\n",
    "* The function should convert the list into a 2D Tensor or numpy array\n",
    "* If the function argument `initial_state` is `None`, then the function should reset the state of the recurrent layer to zeros.\n",
    "* Otherwise, if the function argument `initial_state` is a 2D Tensor or numpy array, assign the value of the internal state of the GRU layer to this argument.\n",
    "* Get the model's prediction (logits) for the last time step only.\n",
    "\n",
    "The function should then return the logits as a 2D numpy array, where the first dimension is equal to 1 (batch size).\n",
    "\n",
    "**Hint:** the internal state of the recurrent can be reset to zeros using the `reset_states` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "3aHg6y44RfUJ"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def get_logits(model, token_sequence, initial_state=None):\n",
    "    \"\"\"\n",
    "    This function takes a model object, a token sequence and an optional initial\n",
    "    state for the recurrent layer. The function should return the logits prediction\n",
    "    for the final time step as a 2D numpy array.\n",
    "    \"\"\"\n",
    "    token_sequence = np.array(token_sequence)\n",
    "    if initial_state is None:\n",
    "        model.layers[1].reset_states()\n",
    "    else:\n",
    "        model.layers[1].reset_states(states = initial_state)\n",
    "    prediction = model.predict(token_sequence)\n",
    "    pred_last = prediction[0, -1, :]\n",
    "    return np.expand_dims(pred_last, 0)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "La2CNRzqRfUN",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.9925365 ,  1.4556051 ,  1.0321405 ,  2.8077443 ,  3.5786397 ,\n",
       "        -0.52930534, -5.514953  ,  3.2020104 ,  7.899821  ,  3.7389245 ,\n",
       "         3.3236823 ,  0.45386034,  3.710796  ,  1.0530921 ,  4.440876  ,\n",
       "         5.338029  , -0.92716163, -0.0764707 ,  3.0653694 , -0.18663046,\n",
       "         3.2825305 , -0.5872105 , -8.903613  , -1.1651022 ,  3.4669793 ,\n",
       "        -1.354363  , -8.128687  ,  0.9908344 , -0.19141316, -3.1248577 ,\n",
       "         1.4933392 , -5.705172  , -7.181185  , -2.9961169 , -3.9349775 ,\n",
       "        -4.741759  , -6.524552  , -6.2391357 , -3.4991548 , -4.2099524 ,\n",
       "        -6.738851  , -7.2057095 , -5.806171  , -3.3677242 , -3.176132  ,\n",
       "        -6.770037  , -2.837829  , -6.991     , -0.8980004 , -7.4625654 ,\n",
       "        -4.451502  , -5.864482  , -7.9080176 , -6.5596433 , -5.143383  ,\n",
       "        -0.82705474,  0.51696557, -2.4826221 , -6.9937005 , -5.7093863 ,\n",
       "        -3.2895062 , -2.1675594 , -5.5908737 , -5.332512  , -4.4342504 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the get_logits function by passing a dummy token sequence\n",
    "\n",
    "dummy_initial_state = tf.random.normal(model.layers[1].states[0].shape)\n",
    "get_logits(model, [[1, 2, 3, 4]], initial_state=dummy_initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KcMB8Yv5RfUQ"
   },
   "source": [
    "You should now write a function that takes a logits prediction similar to the above, uses it to create a categorical distribution, and samples a token from this distribution. The following function takes a 2D numpy array `logits` as an argument, and should return a single integer prediction that is sampled from the categorical distribution. \n",
    "\n",
    "**Hint:** you might find the `tf.random.categorical` function useful for this; see the documentation [here](https://www.tensorflow.org/api_docs/python/tf/random/categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "LObVBMdzRfUS"
   },
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function.\n",
    "# Make sure not to change the function name or arguments.\n",
    "\n",
    "def sample_token(logits):\n",
    "    \"\"\"\n",
    "    This function takes a 2D numpy array as an input, and constructs a \n",
    "    categorical distribution using it. It should then sample from this\n",
    "    distribution and return the sample as a single integer.\n",
    "    \"\"\"\n",
    "    return int(tf.random.categorical(logits, 1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "MrgPsuOYRfUV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the sample_token function by passing dummy logits\n",
    "\n",
    "dummy_initial_state = tf.random.normal(model.layers[1].states[0].shape)\n",
    "dummy_logits = get_logits(model, [[1, 2, 3, 4]], initial_state=dummy_initial_state)\n",
    "sample_token(dummy_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 65)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Q23e4MNpRfUY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 33\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_size = dummy_logits.shape[1]\n",
    "dummy_logits = -np.inf*np.ones((1, logits_size))\n",
    "dummy_logits[0, 20] = 0\n",
    "sample_token(dummy_logits)\n",
    "random_inx = np.random.choice(logits_size, 2, replace=False)\n",
    "random_inx1, random_inx2 = random_inx[0], random_inx[1]\n",
    "print(random_inx1, random_inx2)\n",
    "dummy_logits = -np.inf*np.ones((1, logits_size))\n",
    "dummy_logits[0, random_inx1] = 0\n",
    "dummy_logits[0, random_inx2] = 0\n",
    "sampled_token = []\n",
    "for _ in range(100):\n",
    "    sampled_token.append(sample_token(dummy_logits))\n",
    "    \n",
    "l_tokens, l_counts = np.unique(np.array(sampled_token), return_counts=True)\n",
    "len(l_tokens) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A0FOxOTRfUc"
   },
   "source": [
    "#### Generate text from the model\n",
    "\n",
    "You are now ready to generate text from the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "KgXNTiaYRfUd"
   },
   "outputs": [],
   "source": [
    "# Create a seed string and number of generation steps\n",
    "\n",
    "init_string = 'ROMEO:'\n",
    "num_generation_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "6jm4JeyyRfUf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Ad it revolty, I will rise a bawdy unwon\n",
      "The house men in the Duke of York and minister!\n",
      "Hath then at this him on't to Bianca with the late\n",
      "Of all the end of this cursts, a frowns,\n",
      "To be shew the senate, good my still, be spent;\n",
      "Upon his highness in this, but the outraget?\n",
      "\n",
      "KATHANANIA:\n",
      "Yet possible patience as a bed; and for us to him;\n",
      "For she is disperaced in the offiteron,\n",
      "And hardest mount upon me: gain I were all\n",
      "daughter on the cause? Or look the and that lawful raise\n",
      "And yet that calls upon you, stand baliast\n",
      "That go pard on, after, our own pardon:\n",
      "See that much lived in the sea, or end thy sweet:\n",
      "By the sudden aped limit all;\n",
      "I see a happy faws: but either quick\n",
      "O, fit too unstall'd my fair Baptistle;\n",
      "For cause, look company, and there it may false prince\n",
      "Fit to min that babe's breed, and the rest off from him:\n",
      "With some offence by his chargened body\n",
      "And what can too make speak as mine attempt return\n",
      "by our and lament, Jelusutiful,\n",
      "The bawder men of my son, for thus shalt,\n",
      "So d\n"
     ]
    }
   ],
   "source": [
    "# Use the model to generate a token sequence\n",
    "\n",
    "token_sequence = tokenizer.texts_to_sequences([init_string])\n",
    "initial_state = None\n",
    "input_sequence = token_sequence\n",
    "\n",
    "for _ in range(num_generation_steps):\n",
    "    logits = get_logits(model, input_sequence, initial_state=initial_state)\n",
    "    sampled_token = sample_token(logits)\n",
    "    token_sequence[0].append(sampled_token)\n",
    "    input_sequence = [[sampled_token]]\n",
    "    initial_state = model.layers[1].states[0].numpy()\n",
    "    \n",
    "print(tokenizer.sequences_to_texts(token_sequence)[0][::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9mUfLUyRfUl"
   },
   "source": [
    "Congratulations for completing this programming assignment! In the next week of the course we will see how to build customised models and layers, and make custom training loops."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bản sao của Week 3 Programming Assignment.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "tensor-flow-2-2",
   "graded_item_id": "4eYSM",
   "launcher_item_id": "HEV6h"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
